{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4e1a560-bd01-465e-9d25-c9aba5809ff7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # Create Snowflake Session object\n",
    "import yaml\n",
    "import os\n",
    "import json\n",
    "from snowflake.snowpark.session import Session\n",
    "\n",
    "connection_parameters = json.load(open('connection.json'))\n",
    "\n",
    "session = Session.builder.configs(connection_parameters).create()\n",
    "session.sql_simplifier_enabled = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a63afac0-80c0-4d0d-8672-5d67906ae015",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import numpy as np\n",
    "\n",
    "def create_bandit_visualization(\n",
    "    session,\n",
    "    *,\n",
    "    arms_table=\"ARMS\",\n",
    "    config_table=\"CONFIG\",\n",
    "    events_table=\"EVENTS\",\n",
    "    judge_outputs_table=\"JUDGE_OUTPUTS\"\n",
    "):\n",
    "    \"\"\"\n",
    "    Animated visuals of bandit learning, parameterized by table names.\n",
    "    \"\"\"\n",
    "\n",
    "    # Pull active models + costs\n",
    "    model_rows = session.sql(\n",
    "        f\"\"\"SELECT MODEL_ID, CREDITS_PER_MTOK\n",
    "            FROM {arms_table}\n",
    "            WHERE IS_ACTIVE\n",
    "            ORDER BY MODEL_ID\"\"\"\n",
    "    ).collect()\n",
    "    if not model_rows:\n",
    "        print(\"No active models in ARMS table.\")\n",
    "        return None, None\n",
    "\n",
    "    all_models = [r[0] for r in model_rows]\n",
    "    model_costs = {r[0]: float(r[1]) for r in model_rows}\n",
    "\n",
    "    # perf_weight\n",
    "    perf_weight = float(\n",
    "        session.sql(\n",
    "            f\"SELECT VALUE FROM {config_table} WHERE KEY='perf_weight'\"\n",
    "        ).collect()[0][0]\n",
    "    )\n",
    "\n",
    "    # Exploration events joined to judge outputs\n",
    "    df = session.sql(f\"\"\"\n",
    "        SELECT \n",
    "            e.EVENT_ID,\n",
    "            e.TS,\n",
    "            e.CHOSEN_MODEL,\n",
    "            e.IS_EXPLORATION,\n",
    "            e.REWARD,\n",
    "            jo.JUDGE_MODEL,\n",
    "            jo.PARSED_SCORE,\n",
    "            ROW_NUMBER() OVER (ORDER BY e.TS) AS ROUND_NUMBER\n",
    "        FROM {events_table} e\n",
    "        LEFT JOIN {judge_outputs_table} jo\n",
    "          ON e.EVENT_ID = jo.EVENT_ID\n",
    "        WHERE e.IS_EXPLORATION = TRUE\n",
    "        ORDER BY e.TS, jo.JUDGE_MODEL\n",
    "    \"\"\").to_pandas()\n",
    "\n",
    "    if df.empty:\n",
    "        print(\"No exploration data found!\")\n",
    "        return None, None\n",
    "\n",
    "    performance_data = []\n",
    "    cost_adjusted_data = []\n",
    "\n",
    "    rounds = sorted(df[\"ROUND_NUMBER\"].unique())\n",
    "    model_cumulative = {m: {\"total_score\": 0.0, \"count\": 0} for m in all_models}\n",
    "\n",
    "    for rnum in rounds:\n",
    "        rdf = df[df[\"ROUND_NUMBER\"] == rnum]\n",
    "        chosen_model = rdf[\"CHOSEN_MODEL\"].iloc[0]\n",
    "        avg_score = (\n",
    "            0.0 if rdf[\"PARSED_SCORE\"].isna().all() else float(rdf[\"PARSED_SCORE\"].mean())\n",
    "        )\n",
    "\n",
    "        # update chosen model perf\n",
    "        model_cumulative[chosen_model][\"total_score\"] += avg_score\n",
    "        model_cumulative[chosen_model][\"count\"] += 1\n",
    "\n",
    "        # emit a row per model per round\n",
    "        for m in all_models:\n",
    "            cnt = model_cumulative[m][\"count\"]\n",
    "            cum_avg = (model_cumulative[m][\"total_score\"] / cnt) if cnt > 0 else 0.0\n",
    "\n",
    "            if cum_avg > 0:\n",
    "                ce = 1.0 / model_costs[m] if model_costs[m] > 0 else 0.0\n",
    "                cost_adj = perf_weight * cum_avg + (1 - perf_weight) * ce\n",
    "            else:\n",
    "                cost_adj = 0.0\n",
    "\n",
    "            performance_data.append(\n",
    "                {\n",
    "                    \"round\": rnum,\n",
    "                    \"model\": m,\n",
    "                    \"cumulative_avg_score\": cum_avg,\n",
    "                    \"exploration_count\": cnt,\n",
    "                    \"is_current_round_model\": (m == chosen_model),\n",
    "                }\n",
    "            )\n",
    "            cost_adjusted_data.append(\n",
    "                {\n",
    "                    \"round\": rnum,\n",
    "                    \"model\": m,\n",
    "                    \"cost_adjusted_score\": cost_adj,\n",
    "                    \"exploration_count\": cnt,\n",
    "                    \"is_current_round_model\": (m == chosen_model),\n",
    "                    \"model_cost\": model_costs[m],\n",
    "                    \"pure_performance\": cum_avg,\n",
    "                }\n",
    "            )\n",
    "\n",
    "    perf_df = pd.DataFrame(performance_data)\n",
    "    cost_df = pd.DataFrame(cost_adjusted_data)\n",
    "    if perf_df.empty:\n",
    "        print(\"No performance data to visualize!\")\n",
    "        return None, None\n",
    "\n",
    "    # Pure performance animation\n",
    "    fig1 = px.bar(\n",
    "        perf_df,\n",
    "        x=\"model\",\n",
    "        y=\"cumulative_avg_score\",\n",
    "        color=\"model\",\n",
    "        animation_frame=\"round\",\n",
    "        animation_group=\"model\",\n",
    "        title=\"Multi-Armed Bandit: Pure Judge Performance Over Time\",\n",
    "        labels={\n",
    "            \"cumulative_avg_score\": \"Cumulative Average Judge Score\",\n",
    "            \"model\": \"Model\",\n",
    "            \"round\": \"Exploration Round\",\n",
    "        },\n",
    "        range_y=[0, 1],\n",
    "        height=600,\n",
    "        hover_data=[\"exploration_count\"],\n",
    "    )\n",
    "\n",
    "    # Cost-adjusted animation\n",
    "    ymax = max(3, float(cost_df[\"cost_adjusted_score\"].max() or 0) * 1.1)\n",
    "    fig2 = px.bar(\n",
    "        cost_df,\n",
    "        x=\"model\",\n",
    "        y=\"cost_adjusted_score\",\n",
    "        color=\"model\",\n",
    "        animation_frame=\"round\",\n",
    "        animation_group=\"model\",\n",
    "        title=\"Multi-Armed Bandit: Cost-Adjusted Performance Over Time\",\n",
    "        labels={\n",
    "            \"cost_adjusted_score\": \"Cost-Adjusted Score (Performance + Cost Efficiency)\",\n",
    "            \"model\": \"Model\",\n",
    "            \"round\": \"Exploration Round\",\n",
    "        },\n",
    "        range_y=[0, ymax],\n",
    "        height=600,\n",
    "        hover_data=[\"exploration_count\", \"model_cost\", \"pure_performance\"],\n",
    "    )\n",
    "\n",
    "    # common styling + slower animation\n",
    "    for fig in (fig1, fig2):\n",
    "        fig.update_layout(\n",
    "            title_font_size=20,\n",
    "            xaxis_title_font_size=14,\n",
    "            yaxis_title_font_size=14,\n",
    "            showlegend=True,\n",
    "            template=\"plotly_white\",\n",
    "            xaxis={\"categoryorder\": \"array\", \"categoryarray\": all_models},\n",
    "        )\n",
    "        # slow animation\n",
    "        fig.layout.updatemenus[0].buttons[0].args[1][\"frame\"][\"duration\"] = 1500\n",
    "        fig.layout.updatemenus[0].buttons[0].args[1][\"transition\"][\"duration\"] = 500\n",
    "\n",
    "    # per-frame annotations (n = exploration_count)\n",
    "    for f1, f2 in zip(fig1.frames, fig2.frames):\n",
    "        rnum = int(f1.name)\n",
    "        p_slice = perf_df[perf_df[\"round\"] == rnum]\n",
    "        c_slice = cost_df[cost_df[\"round\"] == rnum]\n",
    "\n",
    "        f1.layout.annotations = [\n",
    "            dict(\n",
    "                x=row[\"model\"],\n",
    "                y=row[\"cumulative_avg_score\"] + 0.05,\n",
    "                text=f\"n={int(row['exploration_count'])}\",\n",
    "                showarrow=False,\n",
    "                font=dict(size=10, color=\"black\"),\n",
    "            )\n",
    "            for _, row in p_slice.iterrows()\n",
    "        ]\n",
    "        f2.layout.annotations = [\n",
    "            dict(\n",
    "                x=row[\"model\"],\n",
    "                y=row[\"cost_adjusted_score\"] + 0.1,\n",
    "                text=f\"n={int(row['exploration_count'])}\",\n",
    "                showarrow=False,\n",
    "                font=dict(size=10, color=\"black\"),\n",
    "            )\n",
    "            for _, row in c_slice.iterrows()\n",
    "        ]\n",
    "\n",
    "    return fig1, fig2\n",
    "\n",
    "\n",
    "def create_detailed_dashboard(\n",
    "    session,\n",
    "    *,\n",
    "    arm_stats_table=\"ARM_STATS\",\n",
    "    events_table=\"EVENTS\"\n",
    "):\n",
    "    \"\"\"\n",
    "    Static dashboard with current scores, exploration/exploitation, EWMA, cost vs perf.\n",
    "    \"\"\"\n",
    "\n",
    "    arm_stats = session.sql(f\"\"\"\n",
    "        SELECT MODEL_ID, PULLS, EWMA_PERF, EWMA_COST, SCORE, LAST_UPDATE\n",
    "        FROM {arm_stats_table}\n",
    "        ORDER BY SCORE DESC\n",
    "    \"\"\").to_pandas()\n",
    "\n",
    "    exploration_df = session.sql(f\"\"\"\n",
    "        SELECT \n",
    "            CHOSEN_MODEL,\n",
    "            IS_EXPLORATION,\n",
    "            COUNT(*) AS COUNT,\n",
    "            AVG(REWARD) AS AVG_REWARD\n",
    "        FROM {events_table}\n",
    "        GROUP BY CHOSEN_MODEL, IS_EXPLORATION\n",
    "        ORDER BY CHOSEN_MODEL, IS_EXPLORATION\n",
    "    \"\"\").to_pandas()\n",
    "\n",
    "    fig = make_subplots(\n",
    "        rows=2,\n",
    "        cols=2,\n",
    "        subplot_titles=[\n",
    "            \"Current Model Scores (ARM_STATS)\",\n",
    "            \"Exploration vs Exploitation Count\",\n",
    "            \"Model Performance (EWMA)\",\n",
    "            \"Cost vs Performance\",\n",
    "        ],\n",
    "        specs=[[{\"type\": \"bar\"}, {\"type\": \"bar\"}], [{\"type\": \"bar\"}, {\"type\": \"scatter\"}]],\n",
    "    )\n",
    "\n",
    "    # Plot 1: Scores\n",
    "    if not arm_stats.empty:\n",
    "        fig.add_trace(\n",
    "            go.Bar(x=arm_stats[\"MODEL_ID\"], y=arm_stats[\"SCORE\"], name=\"Current Score\"),\n",
    "            row=1,\n",
    "            col=1,\n",
    "        )\n",
    "\n",
    "    # Plot 2: Exploration vs exploitation\n",
    "    if not exploration_df.empty:\n",
    "        pivot = exploration_df.pivot(\n",
    "            index=\"CHOSEN_MODEL\", columns=\"IS_EXPLORATION\", values=\"COUNT\"\n",
    "        ).fillna(0)\n",
    "        if False in pivot.columns:\n",
    "            fig.add_trace(\n",
    "                go.Bar(x=pivot.index, y=pivot[False], name=\"Exploitation\"),\n",
    "                row=1,\n",
    "                col=2,\n",
    "            )\n",
    "        if True in pivot.columns:\n",
    "            fig.add_trace(\n",
    "                go.Bar(x=pivot.index, y=pivot[True], name=\"Exploration\"),\n",
    "                row=1,\n",
    "                col=2,\n",
    "            )\n",
    "\n",
    "    # Plot 3: EWMA perf\n",
    "    if not arm_stats.empty:\n",
    "        fig.add_trace(\n",
    "            go.Bar(x=arm_stats[\"MODEL_ID\"], y=arm_stats[\"EWMA_PERF\"], name=\"EWMA Perf\"),\n",
    "            row=2,\n",
    "            col=1,\n",
    "        )\n",
    "\n",
    "    # Plot 4: cost vs perf scatter\n",
    "    if not arm_stats.empty:\n",
    "        fig.add_trace(\n",
    "            go.Scatter(\n",
    "                x=arm_stats[\"EWMA_COST\"],\n",
    "                y=arm_stats[\"EWMA_PERF\"],\n",
    "                mode=\"markers+text\",\n",
    "                text=arm_stats[\"MODEL_ID\"],\n",
    "                textposition=\"top center\",\n",
    "                name=\"Models\",\n",
    "                marker=dict(size=arm_stats[\"PULLS\"] * 3 + 10, opacity=0.7),\n",
    "            ),\n",
    "            row=2,\n",
    "            col=2,\n",
    "        )\n",
    "\n",
    "    fig.update_layout(height=800, title_text=\"Multi-Armed Bandit Dashboard\", showlegend=True)\n",
    "    return fig\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df772b5d-591e-46e9-a7fe-541a86bfdbb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "pure_performance_fig, cost_adjusted_fig = create_bandit_visualization(session)\n",
    "pure_performance_fig.show()\n",
    "cost_adjusted_fig.show()\n",
    "\n",
    "dashboard_fig = create_detailed_dashboard(session)\n",
    "dashboard_fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11a60bbd-b443-4544-8d03-ca7b5a827554",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
